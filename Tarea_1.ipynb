{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"data/itesm.png\"/></center>\n",
    "<h1 style='text-align: center;'><b>Maestría en Inteligencia Artificial Aplicada</b></h1>\n",
    "\n",
    "<h2 style='text-align: center;'><b>Curso: Navegación autónoma</b></h2>\n",
    "<h2 style='text-align: center;'><b>Tecnológico de Monterrey</b></h2>\n",
    "<h2 style='text-align: center;'><b>Prof Titular y Tutor: Dr. David Antonio Torres</b></h2>\n",
    "<h2 style='text-align: center;'><b>Prof Asistente: Maricarmen Vázquez Rojí</b></h2>\n",
    "\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Luis Alfonso Sabanero Esquivel</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01273286</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Jose Mtanous</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A00169781</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b> Guillermo Alfonso Muñiz Hermosillo</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01793101</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Jorge Mariles Estrada</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01335663</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h2 style='text-align: center;'><b>Actividad de la Semana 03</b></h2>\n",
    "<h2 style='text-align: center;'><b>Actividad 2.1 - Detección de carriles en video usando transformada de Hough</b></h1>\n",
    "<h4 style='text-align: right;'>Mayo 2023</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de la Transformada de Hough consta de los siguientes pasos:\n",
    "\n",
    "1. Conversión de la imagen a escala de grises: Primero, se convierte la imagen original a escala de grises, ya que la detección de bordes y la segmentación de la imagen son más fáciles en imágenes en escala de grises.\n",
    "\n",
    "2. Detección de bordes: Se utiliza un operador de detección de bordes, como el operador Sobel o Canny, para detectar los bordes en la imagen en escala de grises. Los bordes son los puntos de la imagen donde la intensidad cambia abruptamente.\n",
    "\n",
    "3. Creación del espacio de Hough: Para cada píxel de borde en la imagen, se traza una curva en el espacio de Hough. La curva representa todas las posibles líneas que podrían pasar a través del píxel de borde. El espacio de Hough es una matriz de dos dimensiones donde cada punto representa una posible línea en la imagen original.\n",
    "\n",
    "4. Acumulación de votos: Se acumulan votos en el espacio de Hough para cada curva. Cada vez que una curva se cruza con otra curva en el espacio de Hough, se incrementa el contador de votos en esa posición del espacio de Hough. Los cruces de curvas representan las posibles líneas en la imagen original.\n",
    "\n",
    "5. Umbralización: Se establece un umbral en el contador de votos para identificar las líneas más prominentes en la imagen original. El umbral determina el número mínimo de votos que debe tener una curva para ser considerada como una línea en la imagen original.\n",
    "\n",
    "6. Dibujar líneas: Finalmente, se extraen los parámetros de las líneas detectadas en el espacio de Hough y se dibujan las líneas en la imagen original. Los parámetros de la línea se calculan a partir de la ecuación de la curva correspondiente en el espacio de Hough.\n",
    "\n",
    "Es importante tener en cuenta que la Transformada de Hough es un algoritmo computacionalmente intensivo y puede requerir mucho tiempo de procesamiento para imágenes grandes o complejas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "def region_interes(img, vertices):\n",
    "    # Creamos una máscara de ceros del mismo tamaño que la imagen\n",
    "    mask = np.zeros_like(img)\n",
    "    # Seleccionamos el color con el que la llenamos, en este caso es negro\n",
    "    match_mask_color = 255\n",
    "    # Creamos el polígono con base en los vértices la máscara y el color\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    # Seleccionamos unicamente los valores en donde la imagen la máscara vale 1\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    # Desplegamos la imagen enmáscarada para fines de depuración de la región de interés\n",
    "    cv2.imshow('Masked', masked_image)\n",
    "    # Regresamos la imagen enmascarada\n",
    "    return masked_image\n",
    "\n",
    "def linea_guia(img, lines):\n",
    "    # Hacemos una copia local de la imagen recortada por la región de interés\n",
    "    img = np.copy(img)\n",
    "    # creamos una matriz del mismo tamaño y dimensiones de la imagen y\n",
    "    # la llenamos con 0 (imagen negra)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Por cada linea que nos regresa el algoritmo de Hough la\n",
    "    # sobre ponemos en la matriz de la imagen en blanco\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            # Dibujamos las lineas usando las coordenas que regresa el algoritmo de\n",
    "            # Hough\n",
    "            cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=10)\n",
    "\n",
    "    # Sobreponemos el frame del video con las lineas que detectamos\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    # regresamos la imagen con las lineas sobrepuestas\n",
    "    return img\n",
    "\n",
    "def frame(img):\n",
    "    # Recortamos la imagen para para mejorar la ejecución del programa\n",
    "    new_width = int(img.shape[1]/1.5)\n",
    "    new_height = int(img.shape[0]/1.5)\n",
    "    \n",
    "    # Calculamos los vértices de la región de interés\n",
    "    # creando un rectángulo usando las nuevas medidas de la imagen\n",
    "    region_of_interest_vertices = [\n",
    "    (0, new_height),\n",
    "    (new_width/2 - new_width/8, new_height/2),\n",
    "    (new_width - new_width / 2,  new_height/2),\n",
    "    (new_width, new_height)\n",
    "    ]\n",
    "\n",
    "    # Ajustamos el tamaño de la imagen\n",
    "    img = cv2.resize(img, (new_width, new_height))\n",
    "    # Convertimos la imagen a escala de grises para facilitar la \n",
    "    # detección de bordes\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Usamos el algoritmo de Canny para detectar los bordes\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    # Obtemos una imagen recortada del frame usando los vértices de\n",
    "    # la región de interés\n",
    "    cropped_image = region_interes(edges,\n",
    "                np.array([region_of_interest_vertices], np.int32),)\n",
    "    # Aplicamos el algoritmo de Hough probabilístico para obtener las lineas\n",
    "    lines = cv2.HoughLinesP(cropped_image,\n",
    "                            rho=1,\n",
    "                            theta=np.pi/180,\n",
    "                            threshold=40,\n",
    "                            lines=np.array([]),\n",
    "                            minLineLength=30,\n",
    "                            maxLineGap=5)\n",
    "    # Sobreponemos la imagen del frame con las lineas\n",
    "    # detectadas por el algoritmo\n",
    "    image_with_lines = linea_guia(img, lines)\n",
    "    # Regresamos el frame con la lineas sobrepuestas\n",
    "    return image_with_lines\n",
    "\n",
    "# Cargamos el video\n",
    "cap = cv2.VideoCapture('test_video.mp4')\n",
    "# Iteramos cuadro por cuadro\n",
    "while cap.isOpened():\n",
    "    ret, img= cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Encontramos la lineas y las sobreponemos sobre el cuadro de video\n",
    "    img_lines = frame(img)\n",
    "\n",
    "    # desplegamos el video con las lineas sobrepuestas\n",
    "    cv2.imshow('frame', img_lines)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
